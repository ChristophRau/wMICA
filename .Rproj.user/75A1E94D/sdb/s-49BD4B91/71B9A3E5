{
    "collab_server" : "",
    "contents" : "library(sem) # for SEM fitting, RAM model format 'mod' and Maximum likelihood indices of SEM fit.\nlibrary(e1071) # for impute: to handle NA in the data by filling in the median\nlibrary(impute) # for imputing missing values\n\n# Updated NEO Functions for Use in R 3.0+\n# 2017 - Christoph Rau\n# Adapted from earlier work by Jason Aten\n\n# Arguments:\n#\n# datCombined = combined data frame containing SNPs, genes and traits on the columns and samples on the rows.\n#\n# snpcols  =  columns of datCombined that contain SNPs (the M in M --> A --> B).  Can also include things like Sex or other binary covariates.\n#\n# genecols = columns of datCombined that contain Gene/Origin values (the A in M --> A --> B)\n#\n# traitcols = columns of datCombined that contain Phenotype/Destination values (the B in M --> A --> B)\n#\n# leo.o.th =  Default Significance Threshold... mostly unimportant in current implementation\n\n#returns a dataframe fitting the 3 variable models SNP -> gene -> trait\n#for each of the supplied snpcols, genecols, and traitcols\n#\nsingle.marker.analysis <-function(datCombined,snpcols,genecols,traitcols, leo.o.th=5,\n                                  pm=neo.get.param(),use.ranks=FALSE,build.multi.marker.to.gene.model=FALSE, impute.na=TRUE)\n{\n  # should we convert the gene and trait cols to ranks first?\n  if (use.ranks) {\n    for (g in genecols) {\n      datCombined[,g]=rank(datCombined[,g])\n    }\n    for (g in traitcols) {\n      datCombined[,g]=rank(datCombined[,g])\n    }\n  }\n\n  cn=colnames(datCombined)\n\n  tsize=length(traitcols)*length(snpcols)*length(genecols)\n\n  M.col=1\n  A.col=2\n  B.col=3\n\n  mlogp.M.AtoB=rep(NA,tsize)\n  mlogp.M.BtoA=rep(NA,tsize)\n  mlogp.M.conf=rep(NA,tsize)\n  mlogp.M.AcollideB=rep(NA,tsize)\n  mlogp.M.BcollideA=rep(NA,tsize)\n\n  RMSEA.AtoB=rep(NA,tsize)\n  RMSEA.BtoA=rep(NA,tsize)\n  RMSEA.conf=rep(NA,tsize)\n  RMSEA.AcollideB=rep(NA,tsize)\n  RMSEA.BcollideA=rep(NA,tsize)\n\n\n  #mlogp.M.AhiddenB=rep(NA,tsize)\n\n  leo.i = rep(NA,tsize)\n  leo.o = rep(NA,tsize)\n  leo.ab.over.ba = rep(NA,tsize)\n  good.o=rep(NA,tsize)\n  good.i=rep(NA,tsize)\n  good.nb=rep(NA,tsize)\n\n  BAc.vs.NextBest = rep(NA,tsize)\n\n  PathAB = rep(NA,tsize)\n  PathBA = rep(NA,tsize)\n  SEPathAB = rep(NA,tsize)\n  SEPathBA = rep(NA,tsize)\n  ZPathAB = rep(NA,tsize)\n  ZPathBA = rep(NA,tsize)\n  PPathAB = rep(NA,tsize)\n  PPathBA = rep(NA,tsize)\n  BLV.AtoB = rep(NA,tsize)\n  BLV.BtoA = rep(NA,tsize)\n  leo.nb.AtoB = rep(NA,tsize)\n  leo.nb.BtoA = rep(NA,tsize)\n  AcollideB.vs.NextBest = rep(NA,tsize)\n\n\n  rn= rep(NA,tsize)\n  rn1= rep(NA,tsize)\n  rn2= rep(NA,tsize)\n  rn3= rep(NA,tsize)\n  rn4= rep(NA,tsize)\n  rn5= rep(NA,tsize)\n\n  ii=0; # store at this row\n  for (i in 1:length(traitcols) ) {\n    t=traitcols[i];\n    for (j in 1:length(snpcols)) {\n      s = snpcols[j];\n      for (k in 1:length(genecols)) {\n        g = genecols[k];\n\n        ii=ii+1\n        xuse=datCombined[,c(s,g,t)]\n        xuse.imp = xuse\n        if (impute.na) { xuse.imp = impute(xuse,what=\"median\") }\n        z=compare.local.sems(pm=pm,M.col,A.col,B.col,xuse.imp)\n\n        mlogp.M.AtoB[ii] = signif( z$mlogp.M.AtoB,3)\n        mlogp.M.BtoA[ii] = signif( z$mlogp.M.BtoA,3)\n        mlogp.M.conf[ii] = signif( z$mlogp.M.conf,3)\n        mlogp.M.AcollideB[ii] = signif( z$mlogp.M.AcollideB,3)\n        mlogp.M.BcollideA[ii] = signif( z$mlogp.M.BcollideA,3)\n        #  mlogp.M.AhiddenB[ii] = signif( z$mlogp.M.AhiddenB,3)\n        rn[ii]=paste(sep=\"\",\"M:\",cn[s],\" to A:\",cn[g],\" to B:\",cn[t])\n\n        rn1[ii]=paste(sep=\"\",\"M:\",cn[s])\n        rn2[ii]=\"to\"\n        rn3[ii]=paste(sep=\"\",\"A:\",cn[g])\n        rn4[ii]=\"to\"\n        rn5[ii]=paste(sep=\"\",\"B:\",cn[t])\n\n        s1.i=z$mlogp.M.conf - z$mlogp.M.AtoB;\n        s2.o=z$mlogp.M.AcollideB - z$mlogp.M.AtoB;\n        leo.i[ii] = signif((s1.i),3)\n        leo.o[ii] = signif((s2.o),3)\n        leo.ab.over.ba[ii] = signif( z$mlogp.M.BtoA - z$mlogp.M.AtoB ,3)\n\n\n        ##\n        ## the new statistics ZPathAB, ZPathBA, z$LEO.NB.BtoA,\n        ## BLV, PearsonCor, PearsonCorP\n        ##\n\n        PathAB[ii] = signif(z$PathAB,3)\n        PathBA[ii] = signif(z$PathBA,3)\n\n        SEPathAB[ii] = signif(z$SEPathAB,3)\n        SEPathBA[ii] = signif(z$SEPathBA,3)\n\n        ZPathAB[ii] = signif(z$ZPathAB,3)\n        ZPathBA[ii] = signif(z$ZPathBA,3)\n\n        PPathAB[ii] = signif(z$PPathAB,3)\n        PPathBA[ii] = signif(z$PPathBA,3)\n\n        BLV.AtoB[ii] = signif(z$BLV.AtoB,3)\n        BLV.BtoA[ii] = signif(z$BLV.BtoA,3)\n\n        RMSEA.AtoB[ii]=signif(z$M.AtoB$RMSEA[1],3)\n        RMSEA.BtoA[ii]=signif(z$M.BtoA$RMSEA[1],3)\n        RMSEA.conf[ii]=signif(z$M.conf$RMSEA[1],3)\n        RMSEA.AcollideB[ii]=signif(z$M.AcollideB$RMSEA[1],3)\n        RMSEA.BcollideA[ii]=signif(z$M.BcollideA$RMSEA[1],3)\n\n        s3.nb = z$LEO.NB.AtoB\n        leo.nb.AtoB[ii] = signif(s3.nb,3)\n        s3.nb.BtoA = z$LEO.NB.BtoA\n        leo.nb.BtoA[ii] = signif(s3.nb.BtoA,3)\n        AcollideB.vs.NextBest[ii] = signif(z$LEO.NB.AcollideB,3)\n\n        good.o[ii] = \" \"\n        if (s2.o >= (leo.o.th)) { good.o[ii]=\"*\" }\n      }}}\n\n  leo.nb.AtoB = signif(leo.nb.AtoB,3)\n  leo.nb.BtoA = signif(leo.nb.BtoA,3)\n\n  df=data.frame(rn1,rn2,rn3,rn4,rn5, leo.nb.AtoB, leo.nb.BtoA, leo.i, leo.o, good.o, leo.ab.over.ba, mlogp.M.AtoB,mlogp.M.BtoA,mlogp.M.conf,mlogp.M.AcollideB,mlogp.M.BcollideA, PathAB, SEPathAB, ZPathAB, PPathAB, PathBA, SEPathBA, ZPathBA, PPathBA, BLV.AtoB, BLV.BtoA, AcollideB.vs.NextBest, RMSEA.AtoB, RMSEA.BtoA, RMSEA.conf, RMSEA.AcollideB, RMSEA.BcollideA)\n\n  colnames(df)[1]=\"model\"\n  colnames(df)[2:5]=\"\"\n  ##  rownames(df) = rn\n  df\n}\n\ntry.failed <- function(x) { inherits(x, \"try-error\") }\n\ntry.sem <- function(pm,ram,covx,N,ana.grad=TRUE) {\n  a=try(autolog.sem(pm,ram,covx,N,analytic.gradient=ana.grad));\n  if (try.failed(a)) {\n    print(paste(\"try.sem: sem() call failed with analytic.gradient=\",ana.grad));\n    print(\"trying the other way (reversing analytical.gradient flag). Model(ram):\");\n    print(ram);\n    a=try(autolog.sem(pm,ram,covx,N,analytic.gradient=!ana.grad));\n    if (try.failed(a)) {\n      print(\"sem() call failed both ways...Setting edge orienting scores to NA for ram:\");\n      cat(ram);\n      a=NA;\n      class(a)=\"FailedSEM\";\n    } else { cat(\"\\n\"); print(paste(\"try.sem() suceeded with analytical.gradient=\",!ana.grad)); }\n  }\n  a\n}\n\n#\n# zeo2detail(): Centralize ZEO computation: so we can alter/play with it, if so desired.\n#\n# N.B.: the four display.Zm1B() like functions have the original ZEO hard coded in them.\n#\nzeo2detail <- function(gp,gk,pa,covx,pm) {\n  z=list();\n  z$cor = pcor(c(gp,gk,c()),covx)\n  z$pcor = pcor(c(gp,gk,pa),covx)\n  z$Zm1B= sqrt(pm$no.obs.Z-pm$fisher.dof.cor)*   fisher1(abs(pcor(c(gp,gk,c()),covx)))\n  z$Zm1BgivenA= sqrt(pm$no.obs.Z-pm$fisher.dof.pcor1)*   fisher1(abs(pcor(c(gp,gk,pa),covx)))\n  z$BLV = z$Zm1B -z$Zm1BgivenA\n\n  z\n}\n\n#\n# since the sem() calls sometimes fail, log them, with the data, to reproduce later if we wish.\n# Also log warning model did not converge calls.\n#\nautolog.sem <- function(gp,gk,pa,covx,pm) {\n  z=list();\n  z$cor = pcor(c(gp,gk,c()),covx)\n  z$pcor = pcor(c(gp,gk,pa),covx)\n  z$Zm1B= sqrt(pm$no.obs.Z-pm$fisher.dof.cor)*   fisher1(abs(pcor(c(gp,gk,c()),covx)))\n  z$Zm1BgivenA= sqrt(pm$no.obs.Z-pm$fisher.dof.pcor1)*   fisher1(abs(pcor(c(gp,gk,pa),covx)))\n  z$BLV = z$Zm1B -z$Zm1BgivenA\n\n  z\n}\n\n#\n# compare.local.sems: return the SEM fitting indices for\n#  a causal, reactive, and confounded model\n#\n# is safe if M.col is a vector too...\n#\n# either supply dataframe x directly....or give both covx and no.obs\n#\ncompare.local.sems <- function(M.col,A.col,B.col,x=NULL,covx=NULL,no.obs=NULL,pm) {\n\n  z=list() # return value\n\n  if(is.null(x) && is.null(covx)) {\n    stop(\"compare.local.sems() called without supply either data matrix x or covariance matrix cov. Aborting.\")\n  }\n  if (is.null(x) && is.null(no.obs)) {\n    stop(\"compare.local.sems() called with covariance matrix but without giving no.obs. Aborting.\")\n  }\n\n  # necessary for AhiddenB code below to always work...\n  if(length(A.col) !=1 || length(B.col) != 1) {\n    stop(\"compare.local.sems called with illegal input: A or B had more or less than 1 variable specified.\")\n  }\n\n\n  if (!is.null(x)) {\n    if (is.null(no.obs)) {\n      no.obs=nrow(x);    # allow no.obs to override the nrow(x), if specified.\n    }\n    cn=colnames(x);\n    subx=data.frame(x[,c(M.col,A.col,B.col)])\n    covx=cov(subx);\n\n  } else {\n    cn=colnames(covx);\n  }\n\n  if (is.null(pm$no.obs.Z)) {pm$no.obs.Z = no.obs} # so we get correct zeo2() scores\n\n  dn=cn[c(M.col,A.col,B.col)];\n  nr=length(dn);\n  M.empty=matrix(rep(0,nr*nr),nrow=nr,dimnames=list(dn,dn));\n\n  # adjust indices to point into new matrix\n  M.col=match(cn[M.col],dn)\n  A.col  =match(cn[A.col],dn)\n  B.col  =match(cn[B.col],dn)\n\n  # model 1\n  M.AtoB=M.empty;\n  M.AtoB[M.col,A.col]=1;\n  M.AtoB[A.col,B.col]=1;\n  #   attr(M.AtoB,\"model\")=1;\n\n  # model 2\n  M.BtoA=M.empty;\n  M.BtoA[M.col,B.col]=1;\n  M.BtoA[B.col,A.col]=1;\n  #   attr(M.BtoA,\"model\")=2;\n\n  # model 3\n  M.conf=M.empty;\n  M.conf[M.col,A.col]=1;\n  M.conf[M.col,B.col]=1;\n  #   attr(M.conf,\"model\")=3;\n\n  # model 4\n  M.AcollideB=M.empty;\n  M.AcollideB[M.col,A.col]=1;\n  M.AcollideB[B.col,A.col]=1;\n  #   attr(M.AcollideB,\"model\")=4;\n\n  # model 5\n  M.BcollideA=M.empty;\n  M.BcollideA[M.col,B.col]=1;\n  M.BcollideA[A.col,B.col]=1;\n  #   attr(M.BcollideA,\"model\")=5;\n\n  # model 6\n  M.AhiddenB=M.empty;\n  M.AhiddenB[M.col,A.col]=1;\n  #   attr(M.AhiddenB,\"model\")=6;\n\n  intra.M.list = generate.intra.ma.pairlist(M.col,c(),pm)\n\n  sem.M.conf = make.ram(M.conf, intra.M.list)\n  sem.M.AtoB = make.ram(M.AtoB, intra.M.list)\n  sem.M.BtoA = make.ram(M.BtoA, intra.M.list)\n  sem.M.BcollideA = make.ram(M.BcollideA, intra.M.list)\n  sem.M.AcollideB = make.ram(M.AcollideB, intra.M.list)\n\n  intra.M.list[[ length(intra.M.list)+1]] = c(A.col,B.col)\n  sem.M.AhiddenB = make.ram(M.AhiddenB, intra.M.list)\n\n  fit.M.conf = summary(try.sem(pm,sem.M.conf$the.ram,covx,N=no.obs))\n  fit.M.AtoB = summary(try.sem(pm,sem.M.AtoB$the.ram,covx,N=no.obs))\n  fit.M.BtoA = summary(try.sem(pm,sem.M.BtoA$the.ram,covx,N=no.obs))\n  fit.M.BcollideA = summary(try.sem(pm,sem.M.BcollideA$the.ram,covx,N=no.obs))\n  fit.M.AcollideB = summary(try.sem(pm,sem.M.AcollideB$the.ram,covx,N=no.obs))\n\n  # fit.M.AhiddenB always takes like 37 iterations and returns the same\n  # value as AcollideB anyway, i.e. the models are not identifiable.\n  #   fit.M.AhiddenB = summary(try.sem(pm,sem.M.AhiddenB$the.ram,covx,N=no.obs))\n\n\n\n\n  z$title=paste(sep=\"\",\"M(\",paste(dn[M.col],collapse=\",\"),\"),A(\",paste(dn[A.col],collapse=\",\"),\"),B(\",paste(dn[B.col],collapse=\",\"),\") local SEM model comparisons to M->A->B.\")\n\n  if (!is.null(x)) {\n    # we want to know how much of A the markers explain, and how much of B\n    form1=paste(dn[A.col],\"~\",paste(collapse=\" + \",dn[M.col]))\n    summy1=summary(lm(as.formula(form1),data=subx))\n    z$A.predicted.by.markers.R.squared = summy1$r.squared\n    z$A.predicted.by.markers.Adjusted.R.squared = summy1$adj.r.squared\n    z$A.predicted.by.markers.formula = form1\n\n    form2 = paste(dn[B.col],\"~\",paste(collapse=\" + \",dn[M.col]))\n    summy2=summary(lm(as.formula(form2),data=subx))\n    z$B.predicted.by.markers.R.squared = summy2$r.squared\n    z$B.predicted.by.markers.Adjusted.R.squared = summy2$adj.r.square\n    z$B.predicted.by.markers.formula = form2\n\n    form3 = paste(dn[B.col],\"~\",dn[A.col])\n    summy3=summary(lm(as.formula(form3),data=subx))\n    z$B.predicted.by.A.gives.R.squared = summy3$r.squared\n    z$B.predicted.by.A.gives.Adjusted.R.squared = summy3$adj.r.squared\n    z$B.predicted.by.A.formula = form3\n  }\n\n  z$M.AtoB=fit.M.AtoB\n  z$M.BtoA=fit.M.BtoA\n  z$M.conf=fit.M.conf\n  z$M.AcollideB=fit.M.AcollideB\n  z$M.BcollideA=fit.M.BcollideA\n\n  #   z$M.AhiddenB=fit.M.AhiddenB\n\n  # for confounding checking...\n  if (length(M.col) ==1) {\n    # single marker version\n    z$zeo.M.A.given.B=zeo2detail(M.col,A.col,B.col,covx,pm) # $BLV is the final score\n    z$zeo.M.B.given.A=zeo2detail(M.col,B.col,A.col,covx,pm) # $BLV\n  } else {\n    # average the BLVs for each marker\n    z$zeo.M.A.given.B=multimarker.zeo2detail(M.col,A.col,B.col,covx,pm) # $BLV is the final score\n    z$zeo.M.B.given.A=multimarker.zeo2detail(M.col,B.col,A.col,covx,pm) # $BLV\n  }\n\n  # convert to log10\n  z$mlogp.M.AtoB=-pchisq(fit.M.AtoB$chisq,1,lower.tail=FALSE,log.p=TRUE)*log.to.log10\n  z$mlogp.M.BtoA=-pchisq(fit.M.BtoA$chisq,1,lower.tail=FALSE,log.p=TRUE)*log.to.log10\n  z$mlogp.M.conf=-pchisq(fit.M.conf$chisq,1,lower.tail=FALSE,log.p=TRUE)*log.to.log10\n\n  z$mlogp.M.AcollideB=-pchisq(fit.M.AcollideB$chisq,1,lower.tail=FALSE,log.p=TRUE)*log.to.log10\n  z$mlogp.M.BcollideA=-pchisq(fit.M.BcollideA$chisq,1,lower.tail=FALSE,log.p=TRUE)*log.to.log10\n\n  #   z$mlogp.M.AhiddenB=-pchisq(fit.M.AhiddenB$chisq,1,lower.tail=FALSE,log.p=TRUE)*log.to.log10\n\n  z$mlogp.in.model.order=c(z$mlogp.M.AtoB,z$mlogp.M.BtoA,z$mlogp.M.conf,z$mlogp.M.AcollideB,z$mlogp.M.BcollideA) #,z$mlogp.M.AhiddenB)\n  so=sort(z$mlogp.in.model.order,decreasing=FALSE,index.return=TRUE)\n  z$ranked.models=so$ix\n  z$ranked.models.mlogp=so$x\n\n  # so far AcollideB and AhiddenB look the same???\n  # For now, then, we EXCLUDE mlogp.M.AhiddenB from the min() below.\n\n\n  ##\n  ## the new statistics ZPathAB, ZPathBA, z$LEO.NB.BtoA,\n  ## BLV, PearsonCor, PearsonCorP\n  ##\n\n\n  z$PathAB = fit.M.AtoB$coeff[4,1]\n  z$PathBA = fit.M.BtoA$coeff[3,1]\n\n  z$SEPathAB = fit.M.AtoB$coeff[4,2]\n  z$SEPathBA = fit.M.BtoA$coeff[3,2]\n\n  z$ZPathAB = fit.M.AtoB$coeff[4,3]\n  z$ZPathBA = fit.M.BtoA$coeff[3,3]\n\n  z$PPathAB = fit.M.AtoB$coeff[4,4]\n  z$PPathBA = fit.M.BtoA$coeff[3,4]\n\n  # Prior to 4 Feb 2008, the right-hand-sides of these two were swapped.\n  # We now switch them to create consistency with SH implementation of BLV.\n  z$BLV.AtoB = z$zeo.M.B.given.A$BLV\n  z$BLV.BtoA = z$zeo.M.A.given.B$BLV\n\n  # for M->A->B\n  z$alt.model.best.min.mlogp = min(z$mlogp.M.conf,z$mlogp.M.BtoA,z$mlogp.M.BcollideA,z$mlogp.M.AcollideB)\n\n  # for M->A<-B\n  z$next.best.min.rev.mlogp = min(z$mlogp.M.conf,z$mlogp.M.BtoA,z$mlogp.M.AtoB,z$mlogp.M.BcollideA)\n\n  # for M->B->A\n  z$next.best.min.M.BtoA.numerator = min(z$mlogp.M.conf, z$mlogp.M.AtoB, z$mlogp.M.AcollideB, z$mlogp.M.BcollideA)\n\n  z$LEO.NB.AtoB = -(z$mlogp.M.AtoB - z$alt.model.best.min.mlogp)\n\n  z$LEO.NB.AcollideB = -(z$mlogp.M.AcollideB - z$next.best.min.rev.mlogp)\n\n  z$LEO.NB.BtoA = -(z$mlogp.M.BtoA - z$next.best.min.M.BtoA.numerator)\n\n  z$main.model.A.to.B.mlogp=z$mlogp.M.AtoB\n  z$p.conf.over.p.AtoB = pchisq(fit.M.conf$chisq,1,lower.tail=FALSE)/pchisq(fit.M.AtoB$chisq,1,lower.tail=FALSE)\n  z$p.conf.over.p.BtoA = pchisq(fit.M.conf$chisq,1,lower.tail=FALSE)/pchisq(fit.M.BtoA$chisq,1,lower.tail=FALSE)\n\n  # the -log10 space version of p.conf.over.p.AtoB becomes LEO.I.AtoB (I for independent (confounded) model comparison)\n  z$LEO.I.AtoB = z$mlogp.M.conf - z$mlogp.M.AtoB\n  z$LEO.I.BtoA = z$mlogp.M.conf - z$mlogp.M.BtoA\n\n  z$LEO.O.AtoB = z$mlogp.M.AcollideB - z$mlogp.M.AtoB\n  z$LEO.O.BtoA = z$mlogp.M.BcollideA - z$mlogp.M.BtoA\n\n\n  # for symmetry of A->B vs B->A to work...we should compare to M.AcollideB\n  z$eo.losem.lod = -(z$mlogp.M.AtoB - z$mlogp.M.AcollideB);\n\n  z\n}\n\n\n# convert from covariance matrix to correlation matrix\n#  reduced from ggm::correlations()\ncovx2cor <- function(covx) {\n  Dg <- 1/sqrt(diag(covx))\n  r <- covx * outer(Dg, Dg)\n  r\n}\n\n\n# fisher's transform to take the correlation coefficient into a normal distribution\nfisher1 <- function(r) {\n  0.5*log((1+r)/(1-r))\n}\n\n# pcor(): partial correlation, copied from ggm so we don't  necessarily need the whole ggm library\npcor <- function (u, S)   #Partial Correlations\n{\n  k <- solve(S[u, u])\n  -k[1, 2]/sqrt(k[1, 1] * k[2, 2])\n}\n\n\n#\n# implement option to add covariances within markers on the m1m2 models\n# (see   pm$add.MA.MB.covar.in.local.sem.four.var.m1m2)\n#\ngenerate.intra.ma.pairlist <- function(MA.col,MB.col,pm) {\n  list.of.hidden.confounded.pair.indices = NULL\n\n  if (pm$add.MA.MB.covar.in.local.sem.four.var.m1m2 & (length(MA.col) > 1 | length(MB.col) > 1)) {\n    list.of.hidden.confounded.pair.indices = list()\n    list.pos = 1\n    if (length(MA.col) > 1) {\n      for (i in 1:(length(MA.col)-1)) {\n        for (j in (i+1):(length(MA.col))) {\n          list.of.hidden.confounded.pair.indices[[ list.pos ]] = c(MA.col[i],MA.col[j])\n          list.pos = list.pos +1\n        }\n      }\n    }\n\n    if (length(MB.col) > 1) {\n      for (i in 1:(length(MB.col)-1)) {\n        for (j in (i+1):(length(MB.col))) {\n          list.of.hidden.confounded.pair.indices[[ list.pos ]] = c(MB.col[i],MB.col[j])\n          list.pos = list.pos +1\n        }\n      }\n    }\n\n  } # end if (pm$add.MA.MB...\n\n  list.of.hidden.confounded.pair.indices\n}\n\n\n# make.ram: turn a dag matrix into a ram specification for MaxLik model fitting.\nmake.ram <- function (m,list.of.hidden.confounded.pair.indices=NULL)\n{\n  cn=colnames(m);\n  nc=length(cn);\n  edgelist=list();\n  my.par=list();\n  my.start=list();\n\n  hidden.count=0;\n  if (!is.null(list.of.hidden.confounded.pair.indices)) {\n    hidden.count=length(list.of.hidden.confounded.pair.indices);\n  }\n\n  # track which variances we have put in the model already\n  var.already.in=vector(length=nc);\n  var.already.in[]=F;\n\n  used.cols=c(); # track the nodes that are used, so we can omit others from the covar matrix and avoid warnings\n  for (j in 1:nc) { for (i in 1:nc) {\n    if (i==j && any(m[,i]!=0, m[i,]!=0) && !var.already.in[i] ) {\n      edgelist=c(edgelist,paste(cn[i],\"<->\",cn[i]));\n      my.par=c(my.par,paste(sep=\"\",\"var.\",cn[i]));\n      my.start=c(my.start,NA);\n      var.already.in[i]=TRUE;\n    } else {\n      if(m[i,j]==1) { edgelist=c(edgelist,paste(cn[i],\"->\",cn[j]));\n      my.par=c(my.par,paste(sep=\"\",\"fr.\",cn[i],\".\",cn[j]));\n      my.start=c(my.start,NA);\n      used.cols=c(i,j,used.cols);\n      }}\n  }}\n\n  # manually add in the covariance between A.col and B.col that is due to hidden var\n  if (!is.null(list.of.hidden.confounded.pair.indices)) {\n    pair.count=1;\n    for (pair in list.of.hidden.confounded.pair.indices) {\n      # old way, which was same as M.AhiddenB (model 4 and 6 were not identifiable)\n      # ...is the best way...!\n      edgelist=c(edgelist,paste(cn[pair[1]],\"<->\",cn[pair[2]]));\n      my.par=c(my.par,paste(sep=\"\",\"covar.\",cn[pair[1]],\".\",cn[pair[2]]));\n      my.start=c(my.start,NA);\n      used.cols=c(pair[1],pair[2],used.cols);\n\n      #              # new way,  works, but same as above\n      #              latent = paste(sep=\"\",\"Lat\",pair.count);\n      #\n      #              edgelist=c(edgelist,paste(latent,\"<->\",latent));\n      #              #my.par=c(my.par,paste(sep=\"\",\"Var.\",latent));\n      #              my.par=c(my.par,NA);\n      #              my.start=c(my.start,1);\n      #\n      #              edgelist=c(edgelist,paste(sep=\"\",latent,\" -> \",cn[pair[1]]));\n      #              edgelist=c(edgelist,paste(sep=\"\",latent,\" -> \",cn[pair[2]]));\n      #              my.par=c(my.par,paste(sep=\"\",latent,\".\",cn[pair[1]]));\n      #              my.par=c(my.par,paste(sep=\"\",latent,\".\",cn[pair[2]]));\n      #              #my.par=c(my.par,NA,NA)\n      #              my.start=c(my.start,1,1);\n      #              used.cols=c(pair[1],pair[2],used.cols);\n\n      if (!var.already.in[pair[1]]) {\n        edgelist=c(edgelist,paste(cn[pair[1]],\"<->\",cn[pair[1]]));\n        my.par=c(my.par,paste(sep=\"\",\"var.\",cn[pair[1]]));\n        my.start=c(my.start,NA);\n        var.already.in[pair[1]]=TRUE;\n      }\n\n      if (!var.already.in[pair[2]]) {\n        edgelist=c(edgelist,paste(cn[pair[2]],\"<->\",cn[pair[2]]));\n        my.par=c(my.par,paste(sep=\"\",\"var.\",cn[pair[2]]));\n        my.start=c(my.start,NA);\n        var.already.in[pair[2]]=TRUE;\n      }\n      pair.count=pair.count+1;\n    }\n  }\n  # end manual addition of hidden covar between A and B\n\n  suppressWarnings({the.ram <- cbind(paste(edgelist), paste(my.par), as.numeric(paste(my.start)))});\n  # important: NA in my.par indicates a fixed variable\n  if (any(is.na(my.par))){ the.ram[which(is.na(my.par)),2]=NA; } # make real NA, not string \"NA\"\n  class(the.ram) <- \"mod\"\n  my.list=list();\n  my.list$the.ram=the.ram\n  my.list$used.cols=unique(used.cols)\n  my.list\n}\n\n\n# neo.get.param(): Parameter defaults for neo functions, neo.get.param()\n#\n# give the user sane default parameters and let them avoid having to type all\n# the defaults out each time\n#\n# logpath gets pre-generated and passed in each time neo() calls.\nneo.get.param=function(logpath=\"neo.logfile\") {\n  list(\n    no.obs.Z=NULL, # if set, over-rides nrow(datCombined) in the\n    # Z-score calculations\n\n    # when fitting multiple marker models in local.sem.four.var.m1m2(), include\n    # covariance terms within the M_A set and within the M_B set?\n    # FALSE is traditional; TRUE may give better or more accurate model fits\n    # because we aren't penalized for some of the markers being correlated\n    # with others in their group. Now confirmed, we default to TRUE now.\n    add.MA.MB.covar.in.local.sem.four.var.m1m2 = TRUE,\n\n    # parameters for using the fisher transform of the correlation\n    # coefficient to (semi)normality.\n    fisher.dof.cor=3, # 3 usually\n    fisher.dof.pcor1=4, # 4 usually\n\n\n    #logfile dir/path.prefix\n    neo.log.file=logpath\n\n  )\n}\n\n\n\n\n\n\n\n\n\n",
    "created" : 1505240383314.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "174|50|189|0|\n196|42|205|0|\n211|43|220|0|\n230|83|444|0|\n449|28|453|0|\n473|58|500|0|\n505|1|589|0|\n",
    "hash" : "2744207320",
    "id" : "71B9A3E5",
    "lastKnownWriteTime" : 1505251685,
    "last_content_update" : 1505251685344,
    "path" : "C:/Work/8 - Code/SuperNeo/NEOFunctions.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 9,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}